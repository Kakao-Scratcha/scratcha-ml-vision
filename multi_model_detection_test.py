#!/usr/bin/env python3
"""
ë‹¤ì¤‘ ëª¨ë¸ ê°ì²´ ê²€ì¶œ ë¹„êµ í…ŒìŠ¤íŠ¸
- ì›ë³¸ ì´ë¯¸ì§€: train_tf ëª¨ë¸
- ë…¸ì´ì¦ˆ ì´ë¯¸ì§€: YOLO11x, EfficientDet, Faster R-CNN
- ë””ë…¸ì´ì§• ì´ë¯¸ì§€: YOLO11x, EfficientDet, Faster R-CNN
"""

import sys
import os
import time
import cv2
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import torch
import torchvision.transforms as transforms
import torchvision
from PIL import Image
import requests
from io import BytesIO

# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

# Windowsì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    # Windowsì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í•œê¸€ í°íŠ¸ ëª©ë¡
    font_list = [
        'Malgun Gothic',      # ë§‘ì€ ê³ ë”• (Windows ê¸°ë³¸)
        'NanumGothic',        # ë‚˜ëˆ”ê³ ë”•
        'NanumBarunGothic',   # ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•
        'AppleGothic',        # ë§¥ìš©
        'Noto Sans CJK KR',   # êµ¬ê¸€ í°íŠ¸
        'DejaVu Sans'         # ê¸°ë³¸ í°íŠ¸
    ]
    
    # ì‹œìŠ¤í…œì— ì„¤ì¹˜ëœ í°íŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    available_fonts = [f.name for f in fm.fontManager.ttflist]
    
    # í•œê¸€ í°íŠ¸ ì°¾ê¸°
    korean_font_found = False
    for font_name in font_list:
        if font_name in available_fonts:
            plt.rcParams['font.family'] = font_name
            plt.rcParams['axes.unicode_minus'] = False
            print(f"âœ“ í•œê¸€ í°íŠ¸ ì„¤ì •: {font_name}")
            korean_font_found = True
            break
    
    if not korean_font_found:
        # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° Windows ê¸°ë³¸ í°íŠ¸ ê°•ì œ ì„¤ì •
        plt.rcParams['font.family'] = 'Malgun Gothic'
        plt.rcParams['axes.unicode_minus'] = False
        print("âš ï¸ ì‹œìŠ¤í…œ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Malgun Gothicì„ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.")
        
except Exception as e:
    print(f"âš ï¸ í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    # ì˜¤ë¥˜ ë°œìƒ ì‹œ Windows ê¸°ë³¸ í°íŠ¸ë¡œ ì„¤ì •
    plt.rcParams['font.family'] = 'Malgun Gothic'
    plt.rcParams['axes.unicode_minus'] = False

# quiz ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'quiz'))

# í•œê¸€ í´ë˜ìŠ¤ëª… ë§¤í•‘
KOREAN_CLASS_NAMES = {
    # COCO 80ê°œ í´ë˜ìŠ¤ (YOLO11x)
    'person': 'ì‚¬ëŒ', 'bicycle': 'ìì „ê±°', 'car': 'ìë™ì°¨', 'motorcycle': 'ì˜¤í† ë°”ì´', 'airplane': 'ë¹„í–‰ê¸°',
    'bus': 'ë²„ìŠ¤', 'train': 'ê¸°ì°¨', 'truck': 'íŠ¸ëŸ­', 'boat': 'ë³´íŠ¸', 'traffic light': 'ì‹ í˜¸ë“±',
    'fire hydrant': 'ì†Œí™”ì „', 'stop sign': 'ì •ì§€ í‘œì§€íŒ', 'parking meter': 'ì£¼ì°¨ ë¯¸í„°ê¸°', 'bench': 'ë²¤ì¹˜',
    'bird': 'ìƒˆ', 'cat': 'ê³ ì–‘ì´', 'dog': 'ê°•ì•„ì§€', 'horse': 'ë§', 'sheep': 'ì–‘', 'cow': 'ì†Œ',
    'elephant': 'ì½”ë¼ë¦¬', 'bear': 'ê³°', 'zebra': 'ì–¼ë£©ë§', 'giraffe': 'ê¸°ë¦°', 'backpack': 'ë°°ë‚­',
    'umbrella': 'ìš°ì‚°', 'handbag': 'í•¸ë“œë°±', 'tie': 'ë„¥íƒ€ì´', 'suitcase': 'ì—¬í–‰ê°€ë°©', 'frisbee': 'í”„ë¦¬ìŠ¤ë¹„',
    'skis': 'ìŠ¤í‚¤', 'snowboard': 'ìŠ¤ë…¸ë³´ë“œ', 'sports ball': 'ìŠ¤í¬ì¸  ê³µ', 'kite': 'ì—°', 'baseball bat': 'ì•¼êµ¬ ë°°íŠ¸',
    'baseball glove': 'ì•¼êµ¬ ê¸€ëŸ¬ë¸Œ', 'skateboard': 'ìŠ¤ì¼€ì´íŠ¸ë³´ë“œ', 'surfboard': 'ì„œí•‘ë³´ë“œ', 'tennis racket': 'í…Œë‹ˆìŠ¤ ë¼ì¼“',
    'bottle': 'ë³‘', 'wine glass': 'ì™€ì¸ì”', 'cup': 'ì»µ', 'fork': 'í¬í¬', 'knife': 'ì¹¼', 'spoon': 'ìˆŸê°€ë½',
    'bowl': 'ê·¸ë¦‡', 'banana': 'ë°”ë‚˜ë‚˜', 'apple': 'ì‚¬ê³¼', 'sandwich': 'ìƒŒë“œìœ„ì¹˜', 'orange': 'ì˜¤ë Œì§€',
    'broccoli': 'ë¸Œë¡œì½œë¦¬', 'carrot': 'ë‹¹ê·¼', 'hot dog': 'í•«ë„ê·¸', 'pizza': 'í”¼ì', 'donut': 'ë„ë„›',
    'cake': 'ì¼€ì´í¬', 'chair': 'ì˜ì', 'couch': 'ì†ŒíŒŒ', 'potted plant': 'í™”ë¶„', 'bed': 'ì¹¨ëŒ€',
    'dining table': 'ì‹íƒ', 'toilet': 'í™”ì¥ì‹¤', 'tv': 'TV', 'laptop': 'ë…¸íŠ¸ë¶', 'mouse': 'ë§ˆìš°ìŠ¤',
    'remote': 'ë¦¬ëª¨ì»¨', 'keyboard': 'í‚¤ë³´ë“œ', 'cell phone': 'íœ´ëŒ€í°', 'microwave': 'ì „ìë ˆì¸ì§€',
    'oven': 'ì˜¤ë¸', 'toaster': 'í† ìŠ¤í„°', 'sink': 'ì‹±í¬ëŒ€', 'refrigerator': 'ëƒ‰ì¥ê³ ', 'book': 'ì±…',
    'clock': 'ì‹œê³„', 'vase': 'ê½ƒë³‘', 'scissors': 'ê°€ìœ„', 'teddy bear': 'ê³°ì¸í˜•', 'hair drier': 'í—¤ì–´ë“œë¼ì´ì–´',
    'toothbrush': 'ì¹«ì†”',
    
    # ì¶”ê°€ ì¼ë°˜ì ì¸ ê°ì²´ë“¤
    'bag': 'ê°€ë°©', 'box': 'ìƒì', 'table': 'í…Œì´ë¸”', 'door': 'ë¬¸', 'window': 'ì°½ë¬¸',
    'tree': 'ë‚˜ë¬´', 'flower': 'ê½ƒ', 'leaf': 'ì', 'grass': 'ì”ë””', 'sky': 'í•˜ëŠ˜',
    'mountain': 'ì‚°', 'river': 'ê°•', 'lake': 'í˜¸ìˆ˜', 'sea': 'ë°”ë‹¤', 'beach': 'í•´ë³€',
    'house': 'ì§‘', 'building': 'ê±´ë¬¼', 'bridge': 'ë‹¤ë¦¬', 'road': 'ë„ë¡œ', 'street': 'ê±°ë¦¬',
    'car': 'ìë™ì°¨', 'truck': 'íŠ¸ëŸ­', 'bus': 'ë²„ìŠ¤', 'train': 'ê¸°ì°¨', 'plane': 'ë¹„í–‰ê¸°',
    'ship': 'ë°°', 'boat': 'ë³´íŠ¸', 'bike': 'ìì „ê±°', 'motorcycle': 'ì˜¤í† ë°”ì´'
}

class MultiModelDetector:
    """ë‹¤ì¤‘ ëª¨ë¸ ê°ì²´ ê²€ì¶œê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        print("=== ë‹¤ì¤‘ ëª¨ë¸ ê°ì²´ ê²€ì¶œê¸° ì´ˆê¸°í™” ===")
        
        # 1. ê¸°ì¡´ YOLO ëª¨ë¸ë“¤ ë¡œë“œ
        from quiz.components.model_manager import ModelManager
        from quiz.components import YOLODetector
        
        model_manager = ModelManager()
        model_paths = model_manager.get_model_paths()
        
        self.yolo_detector = YOLODetector(model_paths['train_model'], model_paths['basic_model'])
        
        # 2. EfficientDet ëª¨ë¸ ë¡œë“œ
        self.efficientdet_model = self._load_efficientdet()
        
        # 3. Faster R-CNN ëª¨ë¸ ë¡œë“œ
        self.faster_rcnn_model = self._load_faster_rcnn()
        
        print("âœ“ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    def _load_efficientdet(self):
        """EfficientDet ëª¨ë¸ ë¡œë“œ (TensorFlow Hub)"""
        try:
            import tensorflow_hub as hub
            import tensorflow as tf
            
            # EfficientDet-D0 ëª¨ë¸ ë¡œë“œ (COCO ì‚¬ì „í•™ìŠµ)
            model = hub.load("https://tfhub.dev/tensorflow/efficientdet/d0/1")
            print("âœ“ EfficientDet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (TensorFlow Hub)")
            return model
        except Exception as e:
            print(f"âš ï¸ EfficientDet ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ëŒ€ì•ˆìœ¼ë¡œ RetinaNet ì‚¬ìš© (EfficientDetì™€ ìœ ì‚¬í•œ êµ¬ì¡°)
            try:
                model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)
                model.eval()
                print("âœ“ RetinaNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (EfficientDet ëŒ€ì‹ )")
                return model
            except Exception as e2:
                print(f"âš ï¸ RetinaNet ëª¨ë¸ ë¡œë“œë„ ì‹¤íŒ¨: {e2}")
                return None
    
    def _load_faster_rcnn(self):
        """Faster R-CNN ëª¨ë¸ ë¡œë“œ"""
        try:
            # Faster R-CNN ëª¨ë¸ ë¡œë“œ (COCO ë°ì´í„°ì…‹)
            model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
            model.eval()
            print("âœ“ Faster R-CNN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            return model
        except Exception as e:
            print(f"âš ï¸ Faster R-CNN ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def detect_with_train_tf(self, image_bytes):
        """train_tf ëª¨ë¸ë¡œ ê²€ì¶œ"""
        try:
            detected_objects = self.yolo_detector.detect_objects(image_bytes)
            return detected_objects
        except Exception as e:
            print(f"train_tf ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def detect_with_yolo11x(self, image_array):
        """YOLO11x ëª¨ë¸ë¡œ ê²€ì¶œ"""
        try:
            # numpy ë°°ì—´ì„ ë°”ì´íŠ¸ë¡œ ë³€í™˜
            if isinstance(image_array, np.ndarray):
                # BGRì„ RGBë¡œ ë³€í™˜
                if len(image_array.shape) == 3 and image_array.shape[2] == 3:
                    image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
                else:
                    image_rgb = image_array
                
                # numpy ë°°ì—´ì„ ë°”ì´íŠ¸ë¡œ ì¸ì½”ë”©
                success, encoded_image = cv2.imencode('.jpg', image_rgb)
                if success:
                    image_bytes = encoded_image.tobytes()
                else:
                    print("YOLO11x: ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
                    return []
            else:
                # ì´ë¯¸ ë°”ì´íŠ¸ì¸ ê²½ìš°
                image_bytes = image_array
            
            detected_objects = self.yolo_detector.detect_objects_with_basic_model(image_bytes)
            return detected_objects
        except Exception as e:
            print(f"YOLO11x ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def detect_with_efficientdet(self, image_array):
        """EfficientDet ëª¨ë¸ë¡œ ê²€ì¶œ (TensorFlow Hub)"""
        if self.efficientdet_model is None:
            return []
        
        try:
            import tensorflow as tf
            import numpy as np
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(image_rgb)
            
            # EfficientDet ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (512x512)
            image_resized = image_pil.resize((512, 512))
            img_np = np.array(image_resized)  # uint8 íƒ€ì…ìœ¼ë¡œ ìœ ì§€
            img_tensor = tf.convert_to_tensor([img_np], dtype=tf.uint8)
            
            # ì¶”ë¡ 
            result = self.efficientdet_model(img_tensor)
            boxes = result["detection_boxes"].numpy()[0]  # [N, 4] (y1, x1, y2, x2)
            scores = result["detection_scores"].numpy()[0]  # [N]
            classes = result["detection_classes"].numpy()[0]  # [N]
            
            detected_objects = []
            h, w = image_array.shape[:2]
            
            # COCO í´ë˜ìŠ¤ëª… ë§¤í•‘
            coco_classes = [
                'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
                'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
                'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
                'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
                'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
            ]
            
            for i, (box, score, class_id) in enumerate(zip(boxes, scores, classes)):
                if score > 0.5:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                    # EfficientDetëŠ” (y1, x1, y2, x2) í˜•ì‹ì´ë¯€ë¡œ (x1, y1, x2, y2)ë¡œ ë³€í™˜
                    y1, x1, y2, x2 = box
                    
                    # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ì¢Œí‘œ ë³€í™˜
                    x1 = int(x1 * w)
                    y1 = int(y1 * h)
                    x2 = int(x2 * w)
                    y2 = int(y2 * h)
                    
                    class_id = int(class_id)
                    class_name = coco_classes[class_id] if class_id < len(coco_classes) else f"class_{class_id}"
                    
                    detected_objects.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(score),
                        'class_name': class_name,
                        'korean_name': class_name  # ì˜ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    })
            
            return detected_objects
            
        except Exception as e:
            print(f"EfficientDet ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def detect_with_faster_rcnn(self, image_array):
        """Faster R-CNN ëª¨ë¸ë¡œ ê²€ì¶œ"""
        if self.faster_rcnn_model is None:
            return []
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image = Image.fromarray(cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB))
            transform = transforms.Compose([
                transforms.ToTensor()
            ])
            
            input_tensor = transform(image)
            
            with torch.no_grad():
                outputs = self.faster_rcnn_model([input_tensor])
            
            # ê²°ê³¼ íŒŒì‹±
            detected_objects = []
            boxes = outputs[0]['boxes'].cpu().numpy()
            scores = outputs[0]['scores'].cpu().numpy()
            labels = outputs[0]['labels'].cpu().numpy()
            
            # COCO í´ë˜ìŠ¤ëª… ë§¤í•‘
            coco_classes = [
                'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',
                'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat',
                'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',
                'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',
                'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
                'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',
                'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',
                'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
                'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'
            ]
            
            for i, (box, score, label) in enumerate(zip(boxes, scores, labels)):
                if score > 0.5:  # ì‹ ë¢°ë„ ì„ê³„ê°’
                    x1, y1, x2, y2 = box
                    class_name = coco_classes[label] if label < len(coco_classes) else f"class_{label}"
                    
                    detected_objects.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': float(score),
                        'class_name': class_name,
                        'korean_name': class_name  # ì˜ì–´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    })
            
            return detected_objects
            
        except Exception as e:
            print(f"Faster R-CNN ê²€ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def get_korean_name(self, class_name):
        """ì˜ì–´ í´ë˜ìŠ¤ëª…ì„ í•œê¸€ë¡œ ë³€í™˜"""
        return KOREAN_CLASS_NAMES.get(class_name, class_name)

class MultiModelComparisonTest:
    """ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.detector = MultiModelDetector()
        from quiz.components.storage_manager import StorageManager
        from quiz.components.image_handler import ImageHandler
        from quiz.components.image_preprocessor import ImagePreprocessor
        
        self.storage_manager = StorageManager()
        self.image_handler = ImageHandler()
        self.preprocessor = ImagePreprocessor()
    
    def run_comparison_test(self, difficulty='medium'):
        """ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"=== ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ({difficulty.upper()} ë‚œì´ë„) ===")
        
        # 1. ì›ë³¸ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        image_key, image_bytes = self.storage_manager.get_random_original_image("images")
        print(f"ì›ë³¸ ì´ë¯¸ì§€: {image_key}")
        
        # 2. ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ train_tf ëª¨ë¸ë¡œ ê²€ì¶œ
        print("ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ train_tf ëª¨ë¸ ê²€ì¶œ ì¤‘...")
        original_detections = self.detector.detect_with_train_tf(image_bytes)
        
        # 3. ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ìƒì„±
        intensity, alpha = self.image_handler.get_random_noise_params(difficulty)
        processed_image_array = self.image_handler.process_image_with_noise(image_bytes, intensity=intensity, alpha=alpha)
        
        # 4. ë””ë…¸ì´ì§• ì´ë¯¸ì§€ ìƒì„±
        denoised_image_array = self.preprocessor.adaptiveDenoising(processed_image_array)
        
        # 5. ê° ì´ë¯¸ì§€ì—ì„œ ë‹¤ì–‘í•œ ëª¨ë¸ë¡œ ê²€ì¶œ
        print("ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ì—ì„œ ë‹¤ì¤‘ ëª¨ë¸ ê²€ì¶œ ì¤‘...")
        noisy_yolo_detections = self.detector.detect_with_yolo11x(processed_image_array)
        noisy_efficientdet_detections = self.detector.detect_with_efficientdet(processed_image_array)
        noisy_faster_rcnn_detections = self.detector.detect_with_faster_rcnn(processed_image_array)
        
        print("ë””ë…¸ì´ì§• ì´ë¯¸ì§€ì—ì„œ ë‹¤ì¤‘ ëª¨ë¸ ê²€ì¶œ ì¤‘...")
        denoised_yolo_detections = self.detector.detect_with_yolo11x(denoised_image_array)
        denoised_efficientdet_detections = self.detector.detect_with_efficientdet(denoised_image_array)
        denoised_faster_rcnn_detections = self.detector.detect_with_faster_rcnn(denoised_image_array)
        
        # 6. ê²°ê³¼ ì‹œê°í™”
        self.create_comparison_visualization(
            image_bytes, processed_image_array, denoised_image_array,
            original_detections, noisy_yolo_detections, noisy_efficientdet_detections, noisy_faster_rcnn_detections,
            denoised_yolo_detections, denoised_efficientdet_detections, denoised_faster_rcnn_detections,
            intensity, alpha, difficulty
        )
        
        return {
            'original_detections': original_detections,
            'noisy_yolo': noisy_yolo_detections,
            'noisy_efficientdet': noisy_efficientdet_detections,
            'noisy_faster_rcnn': noisy_faster_rcnn_detections,
            'denoised_yolo': denoised_yolo_detections,
            'denoised_efficientdet': denoised_efficientdet_detections,
            'denoised_faster_rcnn': denoised_faster_rcnn_detections
        }
    
    def create_comparison_visualization(self, original_bytes, noisy_array, denoised_array,
                                      original_detections, noisy_yolo, noisy_efficientdet, noisy_faster_rcnn,
                                      denoised_yolo, denoised_efficientdet, denoised_faster_rcnn,
                                      intensity, alpha, difficulty):
        """ë¹„êµ ê²°ê³¼ ì‹œê°í™”"""
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
        nparr = np.frombuffer(original_bytes, np.uint8)
        original_image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
        
        # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ì €ì¥ (bbox ì¢Œí‘œ ë³€í™˜ìš©)
        original_height, original_width = original_image.shape[:2]
        
        # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€
        noisy_image = cv2.cvtColor(noisy_array, cv2.COLOR_BGR2RGB)
        
        # ë””ë…¸ì´ì§• ì´ë¯¸ì§€
        denoised_image = cv2.cvtColor(denoised_array, cv2.COLOR_BGR2RGB)
        
        # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°™ì€ í¬ê¸°ë¡œ ë§ì¶¤ (ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€)
        target_height, target_width = noisy_image.shape[:2]
        original_image = cv2.resize(original_image, (target_width, target_height))
        denoised_image = cv2.resize(denoised_image, (target_width, target_height))
        
        # ì›ë³¸ bbox ì¢Œí‘œë¥¼ ë¦¬ì‚¬ì´ì¦ˆëœ í¬ê¸°ì— ë§ê²Œ ë³€í™˜
        scale_x = target_width / original_width
        scale_y = target_height / original_height
        
        for obj in original_detections:
            x1, y1, x2, y2 = obj['bbox']
            obj['bbox'] = [
                int(x1 * scale_x),
                int(y1 * scale_y),
                int(x2 * scale_x),
                int(y2 * scale_y)
            ]
        
        # ì›ë³¸ ê²€ì¶œ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ (ë¹„êµìš©)
        original_classes = set()
        for obj in original_detections:
            class_name = obj.get('korean_name', obj['class_name'])
            original_classes.add(class_name)
        
        def draw_detections(image, detections, title_prefix="", max_detections=3, is_original=False):
            """ì´ë¯¸ì§€ì— ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°"""
            result_image = image.copy()
            
            if detections:
                for i, obj in enumerate(detections[:max_detections]):
                    x1, y1, x2, y2 = obj['bbox']
                    confidence = obj['confidence']
                    class_name = obj.get('korean_name', obj['class_name'])
                    
                    # bbox ì¢Œí‘œ í´ë¨í•‘
                    h, w = result_image.shape[:2]
                    x1 = max(0, min(int(x1), w-1))
                    y1 = max(0, min(int(y1), h-1))
                    x2 = max(0, min(int(x2), w-1))
                    y2 = max(0, min(int(y2), h-1))
                    
                    if x2 - x1 < 5 or y2 - y1 < 5:
                        continue
                    
                    # bbox ìƒ‰ìƒ ê²°ì •
                    if is_original:
                        # ì›ë³¸ ì´ë¯¸ì§€ëŠ” ê¸°ë³¸ ìƒ‰ìƒ
                        color = (0, 255, 0) if confidence > 0.8 else (255, 255, 0) if confidence > 0.6 else (255, 0, 0)
                    else:
                        # ë‹¤ë¥¸ ì´ë¯¸ì§€ë“¤ì€ ì›ë³¸ê³¼ ë¹„êµí•˜ì—¬ ìƒ‰ìƒ ê²°ì •
                        if class_name in original_classes:
                            # ì›ë³¸ì—ì„œë„ ê²€ì¶œëœ ê°ì²´ëŠ” ë¹¨ê°„ìƒ‰ìœ¼ë¡œ ê°•ì¡°
                            color = (0, 0, 255)  # ë¹¨ê°„ìƒ‰ (BGR)
                        else:
                            # ì›ë³¸ì—ì„œ ê²€ì¶œë˜ì§€ ì•Šì€ ê°ì²´ëŠ” ê¸°ë³¸ ìƒ‰ìƒ
                            color = (0, 255, 0) if confidence > 0.8 else (255, 255, 0) if confidence > 0.6 else (255, 0, 0)
                    
                    # bbox ê·¸ë¦¬ê¸°
                    cv2.rectangle(result_image, (x1, y1), (x2, y2), color, 2)
                    
                    # ë¼ë²¨ í…ìŠ¤íŠ¸
                    label = f"{class_name}: {confidence:.2f}"
                    if not is_original and class_name in original_classes:
                        label += " [MATCH]"  # ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ” ê²½ìš° í‘œì‹œ
                    
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
                    
                    # ë¼ë²¨ ë°°ê²½
                    cv2.rectangle(result_image, (x1, y1 - label_size[1] - 10), 
                                (x1 + label_size[0], y1), color, -1)
                    
                    # ë¼ë²¨ í…ìŠ¤íŠ¸
                    cv2.putText(result_image, label, (x1, y1 - 5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            return result_image
        
        # ê·¸ë˜í”„ ì„¤ì • (3x3 ê·¸ë¦¬ë“œ)
        fig = plt.figure(figsize=(18, 15))
        
        # ì²« ë²ˆì§¸ í–‰: ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ë“¤
        # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ - YOLO11x
        ax1 = plt.subplot(3, 3, 1)
        noisy_yolo_with_bbox = draw_detections(noisy_image, noisy_yolo, is_original=False)
        ax1.imshow(noisy_yolo_with_bbox)
        ax1.set_title(f'ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ (YOLO11x)\nê²€ì¶œ: {len(noisy_yolo)}ê°œ', fontsize=12, fontweight='bold')
        ax1.axis('off')
        
        # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ - EfficientDet
        ax2 = plt.subplot(3, 3, 2)
        noisy_eff_with_bbox = draw_detections(noisy_image, noisy_efficientdet, is_original=False)
        ax2.imshow(noisy_eff_with_bbox)
        ax2.set_title(f'ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ (EfficientDet)\nê²€ì¶œ: {len(noisy_efficientdet)}ê°œ', fontsize=12, fontweight='bold')
        ax2.axis('off')
        
        # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ - Faster R-CNN
        ax3 = plt.subplot(3, 3, 3)
        noisy_rcnn_with_bbox = draw_detections(noisy_image, noisy_faster_rcnn, is_original=False)
        ax3.imshow(noisy_rcnn_with_bbox)
        ax3.set_title(f'ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ (Faster R-CNN)\nê²€ì¶œ: {len(noisy_faster_rcnn)}ê°œ', fontsize=12, fontweight='bold')
        ax3.axis('off')
        
        # ë‘ ë²ˆì§¸ í–‰: ë””ë…¸ì´ì§• ì´ë¯¸ì§€ë“¤
        # ë””ë…¸ì´ì§• ì´ë¯¸ì§€ - YOLO11x
        ax4 = plt.subplot(3, 3, 4)
        denoised_yolo_with_bbox = draw_detections(denoised_image, denoised_yolo, is_original=False)
        ax4.imshow(denoised_yolo_with_bbox)
        ax4.set_title(f'ë””ë…¸ì´ì§• ì´ë¯¸ì§€ (YOLO11x)\nê²€ì¶œ: {len(denoised_yolo)}ê°œ', fontsize=12, fontweight='bold')
        ax4.axis('off')
        
        # ë””ë…¸ì´ì§• ì´ë¯¸ì§€ - EfficientDet
        ax5 = plt.subplot(3, 3, 5)
        denoised_eff_with_bbox = draw_detections(denoised_image, denoised_efficientdet, is_original=False)
        ax5.imshow(denoised_eff_with_bbox)
        ax5.set_title(f'ë””ë…¸ì´ì§• ì´ë¯¸ì§€ (EfficientDet)\nê²€ì¶œ: {len(denoised_efficientdet)}ê°œ', fontsize=12, fontweight='bold')
        ax5.axis('off')
        
        # ë””ë…¸ì´ì§• ì´ë¯¸ì§€ - Faster R-CNN
        ax6 = plt.subplot(3, 3, 6)
        denoised_rcnn_with_bbox = draw_detections(denoised_image, denoised_faster_rcnn, is_original=False)
        ax6.imshow(denoised_rcnn_with_bbox)
        ax6.set_title(f'ë””ë…¸ì´ì§• ì´ë¯¸ì§€ (Faster R-CNN)\nê²€ì¶œ: {len(denoised_faster_rcnn)}ê°œ', fontsize=12, fontweight='bold')
        ax6.axis('off')
        
        # ì„¸ ë²ˆì§¸ í–‰: ì›ë³¸ ì´ë¯¸ì§€ + ì°¨íŠ¸ + ì •ë³´
        # ì›ë³¸ ì´ë¯¸ì§€ (train_tf)
        ax7 = plt.subplot(3, 3, 7)
        original_with_bbox = draw_detections(original_image, original_detections, is_original=True)
        ax7.imshow(original_with_bbox)
        ax7.set_title(f'ì›ë³¸ ì´ë¯¸ì§€ (train_tf)\nê²€ì¶œ: {len(original_detections)}ê°œ', fontsize=12, fontweight='bold')
        ax7.axis('off')
        
        # ê²€ì¶œ ê²°ê³¼ ë¹„êµ ì°¨íŠ¸
        ax8 = plt.subplot(3, 3, 8)
        models = ['train_tf\n(ì›ë³¸)', 'YOLO11x\n(ë…¸ì´ì¦ˆ)', 'EfficientDet\n(ë…¸ì´ì¦ˆ)', 'Faster R-CNN\n(ë…¸ì´ì¦ˆ)',
                 'YOLO11x\n(ë””ë…¸ì´ì§•)', 'EfficientDet\n(ë””ë…¸ì´ì§•)', 'Faster R-CNN\n(ë””ë…¸ì´ì§•)']
        detection_counts = [len(original_detections), len(noisy_yolo), len(noisy_efficientdet), len(noisy_faster_rcnn),
                           len(denoised_yolo), len(denoised_efficientdet), len(denoised_faster_rcnn)]
        
        colors = ['blue', 'red', 'green', 'orange', 'red', 'green', 'orange']
        bars = ax8.bar(range(len(models)), detection_counts, color=colors, alpha=0.7)
        ax8.set_xlabel('ëª¨ë¸ë³„ ê²€ì¶œ ê²°ê³¼')
        ax8.set_ylabel('ê²€ì¶œëœ ê°ì²´ ìˆ˜')
        ax8.set_title('ëª¨ë¸ë³„ ê²€ì¶œ ê°ì²´ ìˆ˜ ë¹„êµ')
        ax8.set_xticks(range(len(models)))
        ax8.set_xticklabels(models, rotation=45, ha='right')
        ax8.grid(True, alpha=0.3)
        
        # ê°’ í‘œì‹œ
        for bar, count in zip(bars, detection_counts):
            ax8.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                    str(count), ha='center', va='bottom', fontweight='bold')
        
        # ìƒì„¸ ì •ë³´ í…ìŠ¤íŠ¸
        ax9 = plt.subplot(3, 3, 9)
        ax9.axis('off')
        
        # ê²€ì¶œëœ ê°ì²´ë“¤ ì •ë³´ ìˆ˜ì§‘ (ìƒ‰ìƒ ì •ë³´ í¬í•¨)
        def get_detection_info_with_colors(detections, model_name, is_original=False):
            if not detections:
                return f"{model_name}: ê²€ì¶œ ì‹¤íŒ¨", []
            
            objects = []
            colors = []
            for obj in detections[:3]:  # ìµœëŒ€ 3ê°œë§Œ
                korean_name = obj.get('korean_name', obj['class_name'])
                confidence = obj['confidence']
                
                # ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if not is_original and korean_name in original_classes:
                    objects.append(f"{korean_name}({confidence:.2f})[MATCH]")
                    colors.append('red')
                else:
                    objects.append(f"{korean_name}({confidence:.2f})")
                    colors.append('black')
            
            return f"{model_name}: {', '.join(objects)}", colors
        
        # ê¸°ë³¸ ì •ë³´ í…ìŠ¤íŠ¸
        basic_info = f"""ë‹¤ì¤‘ ëª¨ë¸ ê²€ì¶œ ê²°ê³¼ ë¹„êµ

ë‚œì´ë„: {difficulty.upper()}
ë…¸ì´ì¦ˆ ê°•ë„: {intensity*100:.0f}%
ì•ŒíŒŒ ë¸”ëœë“œ: {alpha*100:.0f}%

ê²€ì¶œ ê²°ê³¼:"""
        
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        ax9.text(0.05, 0.95, basic_info, transform=ax9.transAxes, fontsize=9,
                verticalalignment='top', color='black')
        
        # ê²€ì¶œ ê²°ê³¼ë¥¼ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
        y_pos = 0.70
        detection_results = [
            (original_detections, 'train_tf (ì›ë³¸)', True),
            (noisy_yolo, 'YOLO11x (ë…¸ì´ì¦ˆ)', False),
            (noisy_efficientdet, 'EfficientDet (ë…¸ì´ì¦ˆ)', False),
            (noisy_faster_rcnn, 'Faster R-CNN (ë…¸ì´ì¦ˆ)', False),
            (denoised_yolo, 'YOLO11x (ë””ë…¸ì´ì§•)', False),
            (denoised_efficientdet, 'EfficientDet (ë””ë…¸ì´ì§•)', False),
            (denoised_faster_rcnn, 'Faster R-CNN (ë””ë…¸ì´ì§•)', False)
        ]
        
        for detections, model_name, is_original in detection_results:
            if not detections:
                text = f"{model_name}: ê²€ì¶œ ì‹¤íŒ¨"
                ax9.text(0.05, y_pos, text, transform=ax9.transAxes, 
                        fontsize=8, verticalalignment='top', color='black')
            else:
                # ëª¨ë¸ëª… í‘œì‹œ
                ax9.text(0.05, y_pos, f"{model_name}: ", transform=ax9.transAxes, 
                        fontsize=8, verticalalignment='top', color='black', fontweight='bold')
                
                # ê°ì²´ ì •ë³´ë¥¼ ìƒ‰ìƒê³¼ í•¨ê»˜ í‘œì‹œ
                x_offset = 0.25
                for i, obj in enumerate(detections[:3]):  # ìµœëŒ€ 3ê°œë§Œ
                    korean_name = obj.get('korean_name', obj['class_name'])
                    confidence = obj['confidence']
                    
                    # ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                    if not is_original and korean_name in original_classes:
                        obj_text = f"{korean_name}({confidence:.2f})[MATCH]"
                        color = 'red'
                    else:
                        obj_text = f"{korean_name}({confidence:.2f})"
                        color = 'black'
                    
                    # ì‰¼í‘œ ì¶”ê°€ (ì²« ë²ˆì§¸ê°€ ì•„ë‹Œ ê²½ìš°)
                    if i > 0:
                        ax9.text(0.05 + x_offset, y_pos, ", ", transform=ax9.transAxes, 
                                fontsize=8, verticalalignment='top', color='black')
                        x_offset += 0.02
                    
                    # ê°ì²´ í…ìŠ¤íŠ¸ í‘œì‹œ
                    ax9.text(0.05 + x_offset, y_pos, obj_text, transform=ax9.transAxes, 
                            fontsize=8, verticalalignment='top', color=color)
                    x_offset += len(obj_text) * 0.008
            
            y_pos -= 0.08
        
        # ëª¨ë¸ ì •ë³´
        model_info = """
ëª¨ë¸ ì •ë³´:
â€¢ train_tf: 16ê°œ í´ë˜ìŠ¤ (íŒŒì¸íŠœë‹)
â€¢ YOLO11x: 80ê°œ í´ë˜ìŠ¤ (COCO)
â€¢ EfficientDet: 80ê°œ í´ë˜ìŠ¤ (COCO)
â€¢ Faster R-CNN: 80ê°œ í´ë˜ìŠ¤ (COCO)"""
        
        ax9.text(0.05, y_pos, model_info, transform=ax9.transAxes, fontsize=9,
                verticalalignment='top', color='black')
        
        plt.tight_layout()
        
        # ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = f"multi_model_detection_comparison_{timestamp}.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì €ì¥: {output_path}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ë‹¤ì¤‘ ëª¨ë¸ ê°ì²´ ê²€ì¶œ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test = MultiModelComparisonTest()
    results = test.run_comparison_test('medium')
    
    print("\nğŸ‰ ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ì›ë³¸ ê²€ì¶œ: {len(results['original_detections'])}ê°œ")
    print(f"ë…¸ì´ì¦ˆ YOLO11x: {len(results['noisy_yolo'])}ê°œ")
    print(f"ë…¸ì´ì¦ˆ EfficientDet: {len(results['noisy_efficientdet'])}ê°œ")
    print(f"ë…¸ì´ì¦ˆ Faster R-CNN: {len(results['noisy_faster_rcnn'])}ê°œ")
    print(f"ë””ë…¸ì´ì§• YOLO11x: {len(results['denoised_yolo'])}ê°œ")
    print(f"ë””ë…¸ì´ì§• EfficientDet: {len(results['denoised_efficientdet'])}ê°œ")
    print(f"ë””ë…¸ì´ì§• Faster R-CNN: {len(results['denoised_faster_rcnn'])}ê°œ")

if __name__ == "__main__":
    main()
